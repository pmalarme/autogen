{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Solving mapping between 2 data schema, execution and debugging\n",
    "\n",
    "AutoGen offers conversable LLM agents, which can be used to solved various taks with human or automatic feedback, including tasks that require using tools via code. Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat). \n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to write code and execute the code. He `AssistantAgent` is a LLM-base agent that can write Python code for a user to excute for a given task. `UsderProxyAgent` is an agent which serves as a proxy for the human user to execute the code written by the `AssistantAgent`. Depending on the setting of `human_input_mode` and `max_consecutive_auto_reply`, the `UserProxyAgent` either solicits feedback from the human user or returns auto-feedback based on the result of code execution (success or failure and corresponding outputs) to `AssistantAgent`. `AssistantAgent` will debug the code and suggest new code if the result contains error. The two agents keep communicating to each other until the task is done.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyautogen>=0.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file. Ensure to provide GPT-4 model. If the name of the model is not in the list to filter the dict, please add it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\", \"gpt4-turbo\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Create the code to generate the mapping between two JSON \"schema\" (object).\n",
    "\n",
    "In the example below, let's say we have two JSON objects, `input_schema` and `output_schema`, and we want to generate a mapping between them. This mapping can be useful for data transformation between two REST API for example. We can use AutoGen to generate the code to do the mapping. We are going to see how we can use the agents in AutoGen to write a python script to do the mapping and execute the script.\n",
    "\n",
    "This process involves:\n",
    "* Creating a `AssistantAgent` to serve as the assistant to write the code.\n",
    "* Creating a `UserProxyAgent` to serve as the proxy for the human user to execute the code and to provide feedback to the `AssistantAgent`.\n",
    "\n",
    "When creating the `UserProxyAgent`, we set `human_input_mode` to `\"NEVER\"`, which means the `UserProxyAgent` will never solicit feedback from the human user. Instead, it will return auto-feedback based on the result of code execution (success or failure and corresponding outputs) to `AssistantAgent`. We also set `max_consecutive_auto_reply` to `10`, which means the `UserProxyAgent` will stop replying after 10 consecutive auto-feedback or when `is_termination_msg()` returns `True` for the for the received message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Can you provide a transformation from input schema to output schema?\n",
      "    ### START: INPUT SCHEMA\n",
      "    {\n",
      "        \"user\": {\n",
      "            \"firstName\": string,\n",
      "            \"lastName\": string,\n",
      "            \"birthdate\": date\n",
      "        }\n",
      "    }\n",
      "    ### END: INPUT SCHEMA\n",
      "\n",
      "    ### START: OUTPUT SCHEMA\n",
      "    {\n",
      "        \"fullName\": string,\n",
      "        \"age\": integer\n",
      "    }\n",
      "    ### END: OUTPUT SCHEMA\n",
      "    \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To transform the input schema to the output schema, we need to perform two main tasks:\n",
      "\n",
      "1. Concatenate the `firstName` and `lastName` fields to create the `fullName`.\n",
      "2. Calculate the `age` from the `birthdate`.\n",
      "\n",
      "Here's a Python function that performs this transformation. The function will take a dictionary matching the input schema and return a dictionary matching the output schema.\n",
      "\n",
      "```python\n",
      "# filename: transform_schema.py\n",
      "from datetime import datetime\n",
      "\n",
      "def calculate_age(birthdate):\n",
      "    today = datetime.today()\n",
      "    age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
      "    return age\n",
      "\n",
      "def transform(input_data):\n",
      "    user = input_data['user']\n",
      "    full_name = f\"{user['firstName']} {user['lastName']}\"\n",
      "    birthdate = datetime.strptime(user['birthdate'], '%Y-%m-%d')\n",
      "    age = calculate_age(birthdate)\n",
      "    \n",
      "    output_data = {\n",
      "        \"fullName\": full_name,\n",
      "        \"age\": age\n",
      "    }\n",
      "    return output_data\n",
      "\n",
      "# Example usage:\n",
      "input_schema = {\n",
      "    \"user\": {\n",
      "        \"firstName\": \"John\",\n",
      "        \"lastName\": \"Doe\",\n",
      "        \"birthdate\": \"1990-01-01\"\n",
      "    }\n",
      "}\n",
      "\n",
      "output_schema = transform(input_schema)\n",
      "print(output_schema)\n",
      "```\n",
      "\n",
      "To use this code, save it to a file named `transform_schema.py` and run it with Python. The example usage in the code demonstrates how to call the `transform` function with a sample input dictionary. The `print` statement will output the transformed schema according to the output schema specified.\n",
      "\n",
      "Please execute the code to see the result. If there are any issues, let me know, and I will provide the necessary corrections.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "{'fullName': 'John Doe', 'age': 34}\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The code executed successfully and transformed the input schema into the output schema as expected. The output indicates that a user with the first name \"John\" and the last name \"Doe\", born on January 1st, 1990, has a full name \"John Doe\" and is 34 years old.\n",
      "\n",
      "Please note that the age calculation is based on the current date at the time of execution, and the result may vary depending on when the code is run.\n",
      "\n",
      "If you have any more tasks or need further assistance, feel free to ask. Otherwise, we can consider this task complete.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create an AssistantAgent named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"cache_seed\": 42,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    },  # configuration for autogen's enhanced inference API which is compatible with OpenAI API\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=20,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    },\n",
    ")\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Can you provide a transformation from input schema to output schema?\n",
    "    ### START: INPUT SCHEMA\n",
    "    {\n",
    "        \"user\": {\n",
    "            \"firstName\": string,\n",
    "            \"lastName\": string,\n",
    "            \"birthdate\": date\n",
    "        }\n",
    "    }\n",
    "    ### END: INPUT SCHEMA\n",
    "\n",
    "    ### START: OUTPUT SCHEMA\n",
    "    {\n",
    "        \"fullName\": string,\n",
    "        \"age\": integer\n",
    "    }\n",
    "    ### END: OUTPUT SCHEMA\n",
    "    \"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
